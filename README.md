# Paper Reading

This repo is created to record the papers I have readed, also I will put some useful blogs from other platforms to help you to understand these papers. And the papers I read mainly focus on LLM/LVM/Graph Model.

* Last update: 9/26/2024

## List
### LLM
#### LLM base
| Paper | Published |
|:-------|:-------|
| BERT [[arxiv](https://arxiv.org/abs/1810.04805)] [[repo](https://github.com/google-research/bert)] [[bilibili](https://www.bilibili.com/video/BV1PL411M7eQ/?spm_id_from=333.999.0.0&vd_source=370ed84aad127ddcea55a9ecddb33d4e)] | NAACL 2019 |
| GPT [[gpt-1](https://openai.com/index/language-unsupervised/)] [[gpt-2](https://openai.com/index/better-language-models/)] [[gpt-3](https://openai.com/index/language-models-are-few-shot-learners/)] [[bilibili](https://www.bilibili.com/video/BV1AF411b7xQ/?spm_id_from=333.999.0.0)] | NeurIPS 2020 |

#### Prompt
| Paper | Published |
|:-------|:-------|
| CoT [[arxiv](https://arxiv.org/abs/2201.11903)] [[blog](https://www.promptingguide.ai/techniques/cot)] [[bilibili](https://www.bilibili.com/video/BV1t8411e7Ug/?spm_id_from=333.788&vd_source=370ed84aad127ddcea55a9ecddb33d4e)] | NeurIPS 2022 |
| Zero-shot CoT [[arxiv](https://arxiv.org/abs/2205.11916)] [[blog](https://www.promptingguide.ai/techniques/cot)] | NeurIPS 2022 |
| Self-Consistency [[arxiv](https://arxiv.org/abs/2203.11171)] [[blog](https://www.promptingguide.ai/techniques/consistency)] | ICLR 2023 |
| ToT [[arxiv](https://arxiv.org/abs/2305.10601)] [[repo](https://github.com/princeton-nlp/tree-of-thought-llm)] [[blog](https://www.promptingguide.ai/techniques/tot)] | NeurIPS 2023 |
| Least-to-Most [[arxiv](https://arxiv.org/abs/2205.10625)] [[blog](https://learnprompting.org/docs/intermediate/least_to_most)] | ICLR 2023 |

### LLM4Rec
#### Feature Engineering
| Paper | Published |
|:-------|:-------|
| Mint [[arxiv](https://arxiv.org/abs/2306.02250)] | RecSys 2023 |
